{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from shutil import copyfile\n",
    "import matplotlib\n",
    "\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.convolutional import ZeroPadding2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers import add\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "#from imutils import paths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data set can be downloaded from ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
    "# Set the dir path in 'top_path' variable\n",
    "top_path = 'E:\\\\Malaria dataset'\n",
    "cell_img = 'cell_images'\n",
    "base_dir = os.path.sep.join([top_path, cell_img])\n",
    "uninfect = 'Uninfected'\n",
    "infect = 'Parasitized'\n",
    "\n",
    "file_list = []\n",
    "for each in os.listdir(base_dir+'\\\\'+uninfect):\n",
    "    file_list.append(base_dir+'\\\\'+uninfect+'\\\\'+each)\n",
    "for each in os.listdir(base_dir+'\\\\'+infect):\n",
    "    file_list.append(base_dir+'\\\\'+infect+'\\\\'+each)\n",
    "random.shuffle(file_list)\n",
    "random.shuffle(file_list)\n",
    "random.shuffle(file_list)\n",
    "random.shuffle(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8\n",
    "val_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "if train_split+val_split+test_split != 1:\n",
    "    raise Exception('Data splits do not equal to 1')\n",
    "    \n",
    "train_files = file_list[:int(len(file_list)*train_split)]\n",
    "test_files = file_list[int(len(file_list)*train_split) : int(len(file_list)*(train_split+test_split))]\n",
    "val_files = file_list[int(len(file_list)*(train_split+test_split)) : ]\n",
    "\n",
    "train_dir = 'training_data'\n",
    "test_dir = 'testing_data'\n",
    "val_dir = 'val_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLength = len(train_files)\n",
    "testLength = len(test_files)\n",
    "valLength = len(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fil in train_files:\n",
    "    label = fil.split(os.path.sep)[-2]\n",
    "    name = fil.split(os.path.sep)[-1]\n",
    "    dest = os.path.sep.join([top_path, train_dir, label, name])\n",
    "    copyfile(fil, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fil in test_files:\n",
    "    label = fil.split(os.path.sep)[-2]\n",
    "    name = fil.split(os.path.sep)[-1]\n",
    "    dest = os.path.sep.join([top_path, test_dir, label, name])\n",
    "    copyfile(fil, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fil in val_files:\n",
    "    label = fil.split(os.path.sep)[-2]\n",
    "    name = fil.split(os.path.sep)[-1]\n",
    "    dest = os.path.sep.join([top_path, val_dir, label, name])\n",
    "    copyfile(fil, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    @staticmethod\n",
    "    def residual_module(data, K, stride, chanDim, red=False, reg=0.0001,\n",
    "                        bnEps=2e-5, bnMom=0.9):\n",
    "        shortcut = data\n",
    "        \n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        conv1 = Conv2D(int(K*0.25) , (1,1), use_bias=False,\n",
    "                      kernel_regularizer=l2(reg))(act1)\n",
    "        \n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv1)\n",
    "        act2 = Activation(\"relu\")(bn2)\n",
    "        conv2 = Conv2D(int(K *0.25), (3,3), strides=stride, padding=\"same\",\n",
    "                      use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
    "        \n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1,1), use_bias=False, kernel_regularizer=l2(reg))(act3)\n",
    "        \n",
    "        if red:\n",
    "            shortcut = Conv2D(K, (1,1), strides=stride, use_bias=False,\n",
    "                             kernel_regularizer=l2(reg))(act1)\n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, stages, filters,\n",
    "             reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        \n",
    "        inputShape = (height,width,depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
    "        \n",
    "        x = Conv2D(filters[0], (5,5), use_bias=False, padding=\"same\",\n",
    "                   kernel_regularizer=l2(reg))(x)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = ZeroPadding2D((1,1))(x)\n",
    "        x = MaxPooling2D((3,3), strides=(2,2))(x)\n",
    "        \n",
    "        for i in range(0, len(stages)):\n",
    "            stride = (1,1) if i == 0 else (2,2)\n",
    "            x = ResNet.residual_module(x, filters[i+1], stride,\n",
    "                                      chanDim, red=True, bnEps=bnEps,\n",
    "                                      bnMom=bnMom)\n",
    "            for j in range(0, stages[i] - 1):\n",
    "                x = ResNet.residual_module(x, filters[i+1],\n",
    "                                          (1,1), chanDim, bnEps=bnEps,\n",
    "                                          bnMom=bnMom)\n",
    "                \n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps,\n",
    "                              momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = AveragePooling2D((8,8))(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "        \n",
    "        model = Model(inputs, x, name=\"resnet\")\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "INIT_LR = 1e-1\n",
    "BS = 32\n",
    "\n",
    "def poly_decay(epoch):\n",
    "    max_epoch = NUM_EPOCHS\n",
    "    baseLR = INIT_LR\n",
    "    power = 1.0\n",
    "    \n",
    "    alpha = baseLR * (1 - (epoch / float(max_epoch)))**power\n",
    "    \n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainAug = ImageDataGenerator(rescale=1/255.0,\n",
    "                             rotation_range=20,\n",
    "                             zoom_range=0.05,\n",
    "                             width_shift_range=0.05,\n",
    "                             height_shift_range=0.05,\n",
    "                             shear_range=0.05,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode=\"nearest\")\n",
    "\n",
    "valAug = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22047 images belonging to 2 classes.\n",
      "Found 2756 images belonging to 2 classes.\n",
      "Found 2755 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trainGen = trainAug.flow_from_directory(\n",
    "    os.path.sep.join([top_path,train_dir]),\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=True,\n",
    "    batch_size=BS)\n",
    "\n",
    "valGen = valAug.flow_from_directory(\n",
    "    os.path.sep.join([top_path,val_dir]),\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS)\n",
    "\n",
    "testGen = valAug.flow_from_directory(\n",
    "    os.path.sep.join([top_path,test_dir]),\n",
    "    class_mode=\"categorical\",\n",
    "    target_size=(64,64),\n",
    "    color_mode=\"rgb\",\n",
    "    shuffle=False,\n",
    "    batch_size=BS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\anaconda\\envs\\withKeras\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = ResNet.build(64, 64, 3, 2, (3, 4, 6),\n",
    "                     (64, 128, 256, 512), reg=0.0005)\n",
    "opt = SGD(lr=INIT_LR, momentum=0.9)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = [LearningRateScheduler(poly_decay)]\n",
    "H = model.fit_generator(trainGen, steps_per_epoch=trainLength//BS,\n",
    "                       validation_data=valGen,\n",
    "                       validation_steps=valLength//BS,\n",
    "                       epochs=NUM_EPOCHS, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "otp = model.predict_generator(testGen,\n",
    "                              steps=testLength//BS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
